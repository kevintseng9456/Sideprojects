{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此專案(face_project)環境\n",
    "1.虛擬環境\n",
    "2.使用python3.9,請確認右上角為python39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('C:\\\\Users\\\\Leo\\\\Anaconda3\\\\envs\\\\face_project\\\\Lib\\\\site-packages')\n",
    "print(\"path -->\",sys.path,\"\\n\")\n",
    "print(\"V -->\",sys.version,\"\\n\")\n",
    "\n",
    "#確認是否使用虛擬環境內的python版本，如果不是須設定\n",
    "print(\"exe -->\",sys.executable,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------收集照片用\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2\n",
    "\n",
    "#必須先有pic資料夾以及who資料夾(who改成人員名稱)\n",
    "IMAGES_PATH = os.path.join('pic','Apple')\n",
    "#30，為拍照張數\n",
    "number_images = 30\n",
    "#開鏡頭\n",
    "cap = cv2.VideoCapture(0)\n",
    "#抓取照片，並存入資料夾底下./pic/who\n",
    "\n",
    "for imgnum in range(number_images):\n",
    "    print('Collecting image {}'.format(imgnum))\n",
    "    ret, frame = cap.read()\n",
    "    imgname = os.path.join(IMAGES_PATH,f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(imgname, frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # 當按下Esc結束迴圈\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k==27:\n",
    "        break\n",
    "\n",
    "#關閉相機\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------即時辨識打卡系統(openccv + arcface)\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import time\n",
    "\n",
    "#opencv人臉辨識檔案\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "#開啟相機\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#定義顯示文字參數\n",
    "text = ''\n",
    "name_org = (40, 80)\n",
    "time_org = (40, 90)\n",
    "fontFace = cv2.FONT_HERSHEY_COMPLEX\n",
    "fontScale = 1\n",
    "fontcolor = (0, 255, 0) # BGR\n",
    "thickness = 2 \n",
    "lineType = 4\n",
    "bottomLeftOrigin = 1\n",
    "\n",
    "#開始辨識\n",
    "while True:\n",
    "    #讀取影像\n",
    "    _, img_raw = cap.read()\n",
    "    #轉成灰階模式\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #此方法的任務是檢測不同大小的對象，並返回矩形的列表\n",
    "    #詳細解釋可參考 https://blog.csdn.net/leaf_zizi/article/details/107637433\n",
    "    faces = face_cascade.detectMultiScale(img_raw, 1.1, 8)\n",
    "    # print(\"faces-->\",faces)\n",
    "\n",
    "    for i in range(len(faces)):\n",
    "        try:\n",
    "            #臉部位置\n",
    "            face_x, face_y, face_w, face_h = faces[i]\n",
    "            \n",
    "            #抓出人臉\n",
    "            img = img_raw[int(face_y):int(face_y+face_h), int(face_x):int(face_x+face_w)]\n",
    "\n",
    "            #標記人臉範圍，名字位置，時間位置\n",
    "            # for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(img_raw, (face_x, face_y), (face_x+face_w, face_y+face_h), (0, 255, 0), 2)\n",
    "            name_org = (face_x, face_y-30)\n",
    "            time_org = (face_x, face_y)\n",
    "                \n",
    "            #透過arcface辨識，img為辨識目標位置，db_path為影像資料庫位置\n",
    "            df = DeepFace.find(img, db_path = \"pic\", model_name = 'ArcFace',enforce_detection=False)\n",
    "            print(df.head())\n",
    "\n",
    "            #驗證圖片\n",
    "            # result = DeepFace.verify(img, \"pic\", model_name = 'ArcFace',enforce_detection=False)\n",
    "            # print(result)\n",
    "            \n",
    "            try:\n",
    "                #抓取辨識名字\n",
    "                name = df.loc[0].values[0].split('/')[-2].split('\\\\')[-1]\n",
    "                #抓取當前時間\n",
    "                Time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "\n",
    "                #顯示名字、時間到畫面上\n",
    "                cv2.putText(img_raw, name, name_org, fontFace, fontScale, fontcolor, thickness, lineType)\n",
    "                cv2.putText(img_raw, Time, time_org, fontFace, fontScale, fontcolor, thickness, lineType)\n",
    "\n",
    "                #打卡紀錄\n",
    "                punch_path = 'output.txt'\n",
    "                with open(punch_path, 'a') as f:\n",
    "                    f.write(f\"{name} at {Time} punch cad.\\n\")\n",
    "\n",
    "                print(f\"我辨識這位是 {name}。\")\n",
    "            except:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "    #正常視窗大小\n",
    "    cv2.namedWindow('img', cv2.WINDOW_NORMAL)\n",
    "    #秀出圖片                                           \n",
    "    cv2.imshow('img', img_raw)                     \n",
    "\n",
    "    # 當按下Esc結束迴圈\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k==27:\n",
    "        break\n",
    "        \n",
    "#關閉相機\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------輸入照片圖片模式(retinaface + arcface)\n",
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import time\n",
    "\n",
    "#圖像辨識-------------------------------------------------------\n",
    "\n",
    "#讀取圖像\n",
    "img = cv2.imread(\"test_img\\\\0002.jpg\")\n",
    "\n",
    "\n",
    "#轉正臉\n",
    "# faces2 = RetinaFace.extract_faces(img, align = True)\n",
    "# for face in faces2:\n",
    "#     plt.imshow(face)\n",
    "#     plt.show()\n",
    "\n",
    "#透過RetinaFace辨識人像，默認閾值設置為 0.9。如果要以低解析度檢測人臉，則可以降低它。\n",
    "faces  = RetinaFace.detect_faces(img,threshold = 0.9)\n",
    "\n",
    "#圖像參數\n",
    "faces.keys()\n",
    "\n",
    "try:\n",
    "    #取出參數\n",
    "    for key in faces.keys():\n",
    "\n",
    "        #第X張人像總參數\n",
    "        identity = faces[key]\n",
    "\n",
    "        #人像矩形邊界參數\n",
    "        facial_area = identity[\"facial_area\"]\n",
    "\n",
    "        #特徵標記\n",
    "        landmarks = identity[\"landmarks\"]\n",
    "\n",
    "        #將numpy.float數值轉換為int，因為cv2.circle參數center格式需要int\n",
    "        le = tuple(map(int,landmarks[\"left_eye\"]))\n",
    "        re = tuple(map(int,landmarks[\"right_eye\"]))\n",
    "        n  = tuple(map(int,landmarks[\"nose\"]))\n",
    "        lm = tuple(map(int,landmarks[\"mouth_left\"]))\n",
    "        rm = tuple(map(int,landmarks[\"mouth_right\"]))\n",
    "        \n",
    "        #框出人像\n",
    "        cv2.rectangle(img, (facial_area[2],facial_area[3]),(facial_area[0],facial_area[1]),(255,255,255),1)\n",
    "        #標記左眼位置\n",
    "        cv2.circle(img, le, 1, (0, 0, 255), -1)\n",
    "        #標記右眼位置\n",
    "        cv2.circle(img, re, 1, (0, 0, 255), -1)\n",
    "        #標記鼻子位置\n",
    "        cv2.circle(img, n, 1, (0, 0, 255), -1)\n",
    "        #標記左嘴角位置\n",
    "        cv2.circle(img, lm, 1, (0, 0, 255), -1)\n",
    "        #標記右嘴角位置\n",
    "        cv2.circle(img, rm, 1, (0, 0, 255), -1)   \n",
    "\n",
    "    #設定顯示圖片大小\n",
    "    plt.figure(figsize = (5,5))\n",
    "    #使圖片顯示完整\n",
    "    plt.imshow(img[:,:,::-1])\n",
    "    #顯示圖片\n",
    "    plt.show()\n",
    "\n",
    "#-------find & verfiy distance太大的時候，建議可以縮小threshold的大小-----------\n",
    "#-------修改threshold檔案為\\deepface\\commons\\distance.py----------------------\n",
    "\n",
    "    #透過arcface辨識，img為辨識目標位置，db_path為影像資料庫位置\n",
    "    #find()預設有轉正臉\n",
    "    df = DeepFace.find(img, db_path = \"pic\\\\Ester\", model_name = 'ArcFace',detector_backend = 'retinaface',enforce_detection=False)\n",
    "    #顯示比對照片路徑&consine值\n",
    "    print(df.head())\n",
    "\n",
    "    #驗證圖片\n",
    "    result = DeepFace.verify(img, \"test_img\\\\0009.jpg\", model_name = 'ArcFace',detector_backend = 'retinaface',enforce_detection=False)\n",
    "    print(result)\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "    #讀取圖像\n",
    "    img2 = cv2.imread(\"test_img\\\\0009.jpg\")\n",
    "    #設定顯示圖片大小\n",
    "    plt.figure(figsize = (5,5))\n",
    "    #使圖片顯示完整\n",
    "    plt.imshow(img2[:,:,::-1])\n",
    "    #顯示圖片\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    try:\n",
    "        #抓取辨識名字\n",
    "        name = df.loc[0].values[0].split('/')[-2].split('\\\\')[-1]\n",
    "        #抓取當前時間\n",
    "        Time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        # cv2.putText(img, name, name_org, fontFace, fontScale, fontcolor, thickness, lineType)\n",
    "        # cv2.putText(img, Time, time_org, fontFace, fontScale, fontcolor, thickness, lineType)\n",
    "        print(f\"我辨識這位是 {name}。\")\n",
    "    except:\n",
    "        pass\n",
    "except:\n",
    "    print(\"!! 辨識失敗 !!\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------輸入影片模式(retinaface + arcface)\n",
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import time\n",
    "\n",
    "#影像辨識-------------------------------------------------------\n",
    "cap = cv2.VideoCapture('test.mp4')\n",
    "\n",
    "while(True):\n",
    "    _, img = cap.read()\n",
    "    try:\n",
    "\n",
    "    #圖像辨識-------------------------------------------------------\n",
    "\n",
    "    #透過RetinaFace辨識人像，默認閾值設置為 0.9。如果要以低解析度檢測人臉，則可以降低它。\n",
    "        faces  = RetinaFace.detect_faces(img,threshold = 0.9)\n",
    "\n",
    "        #圖像參數\n",
    "        faces.keys()\n",
    "        \n",
    "        #取出參數\n",
    "        for key in faces.keys():\n",
    "\n",
    "            #第X張人像總參數\n",
    "            identity = faces[key]\n",
    "\n",
    "            #人像矩形邊界參數\n",
    "            facial_area = identity[\"facial_area\"]\n",
    "\n",
    "            #特徵標記\n",
    "            landmarks = identity[\"landmarks\"]\n",
    "\n",
    "            #將numpy.float數值轉換為int，因為cv2.circle參數center格式需要int\n",
    "            le = tuple(map(int,landmarks[\"left_eye\"]))\n",
    "            re = tuple(map(int,landmarks[\"right_eye\"]))\n",
    "            n  = tuple(map(int,landmarks[\"nose\"]))\n",
    "            lm = tuple(map(int,landmarks[\"mouth_left\"]))\n",
    "            rm = tuple(map(int,landmarks[\"mouth_right\"]))\n",
    "            \n",
    "            #框出人像\n",
    "            cv2.rectangle(img, (facial_area[2],facial_area[3]),(facial_area[0],facial_area[1]),(255,255,255),1)\n",
    "            #標記左眼位置\n",
    "            cv2.circle(img, le, 1, (0, 0, 255), -1)\n",
    "            #標記右眼位置\n",
    "            cv2.circle(img, re, 1, (0, 0, 255), -1)\n",
    "            #標記鼻子位置\n",
    "            cv2.circle(img, n, 1, (0, 0, 255), -1)\n",
    "            #標記左嘴角位置\n",
    "            cv2.circle(img, lm, 1, (0, 0, 255), -1)\n",
    "            #標記右嘴角位置\n",
    "            cv2.circle(img, rm, 1, (0, 0, 255), -1)   \n",
    "\n",
    "        # #設定顯示圖片大小\n",
    "        # plt.figure(figsize = (5,5))\n",
    "        # #使圖片顯示完整\n",
    "        # plt.imshow(img[:,:,::-1])\n",
    "        # #顯示圖片\n",
    "        # plt.show()\n",
    "\n",
    "        #透過arcface辨識，img為辨識目標位置，db_path為影像資料庫位置\n",
    "        df = DeepFace.find(img, db_path = \"pic\\\\Ester\", model_name = 'ArcFace',detector_backend = 'retinaface',enforce_detection=False)\n",
    "        print(df.head())\n",
    "\n",
    "        #驗證圖片\n",
    "        result = DeepFace.verify(img, \"pic\\\\Ester\\\\ester2000.jpg\", model_name = 'ArcFace',detector_backend = 'retinaface',enforce_detection=False)\n",
    "        print(result)\n",
    "        \n",
    "        try:\n",
    "            #抓取辨識名字\n",
    "            name = df.loc[0].values[0].split('/')[-2].split('\\\\')[-1]\n",
    "            #抓取當前時間\n",
    "            Time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "            # cv2.putText(img, name, name_org, fontFace, fontScale, fontcolor, thickness, lineType)\n",
    "            # cv2.putText(img, Time, time_org, fontFace, fontScale, fontcolor, thickness, lineType)\n",
    "            print(f\"我辨識這位是 {name}。\")\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        print(\"!! 辨識失敗 !!\")\n",
    "            \n",
    "    # 當按下Esc結束迴圈\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k==27:\n",
    "        break\n",
    "    cv2.imshow(\"video\",img)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下為人臉辨識4大步驟拆解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----抓臉\n",
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import time\n",
    "\n",
    "#讀取圖像\n",
    "img = cv2.imread(\"test_img\\\\0009.jpg\")\n",
    "#透過RetinaFace辨識人像，默認閾值設置為 0.9。如果要以低解析度檢測人臉，則可以降低它。\n",
    "faces  = RetinaFace.detect_faces(img,threshold = 0.9)\n",
    "\n",
    "#圖像參數\n",
    "#'score'越高此圖越像人臉， 'facial_area'座標參數，'landmarks': 包含眼睛鼻子嘴角的座標\n",
    "print(\"faces --> \",faces,\"\\n\")\n",
    "# print(\"faces.keys() --> \",faces.keys(),\"\\n\")\n",
    "\n",
    "#取出參數\n",
    "for key in faces.keys():\n",
    "\n",
    "    #第X張人像總參數\n",
    "    identity = faces[key]\n",
    "\n",
    "    #人像矩形邊界參數\n",
    "    facial_area = identity[\"facial_area\"]\n",
    "\n",
    "    #特徵標記\n",
    "    landmarks = identity[\"landmarks\"]\n",
    "\n",
    "    #將numpy.float數值轉換為int，因為cv2.circle參數center格式需要int\n",
    "    le = tuple(map(int,landmarks[\"left_eye\"]))\n",
    "    re = tuple(map(int,landmarks[\"right_eye\"]))\n",
    "    n  = tuple(map(int,landmarks[\"nose\"]))\n",
    "    lm = tuple(map(int,landmarks[\"mouth_left\"]))\n",
    "    rm = tuple(map(int,landmarks[\"mouth_right\"]))\n",
    "    \n",
    "    #框出人像\n",
    "    cv2.rectangle(img, (facial_area[2],facial_area[3]),(facial_area[0],facial_area[1]),(255,255,255),1)\n",
    "    #標記左眼位置\n",
    "    cv2.circle(img, le, 1, (0, 0, 255), -1)\n",
    "    #標記右眼位置\n",
    "    cv2.circle(img, re, 1, (0, 0, 255), -1)\n",
    "    #標記鼻子位置\n",
    "    cv2.circle(img, n, 1, (0, 0, 255), -1)\n",
    "    #標記左嘴角位置\n",
    "    cv2.circle(img, lm, 1, (0, 0, 255), -1)\n",
    "    #標記右嘴角位置\n",
    "    cv2.circle(img, rm, 1, (0, 0, 255), -1)   \n",
    "#設定顯示圖片大小\n",
    "plt.figure(figsize = (5,5))\n",
    "#使圖片顯示完整\n",
    "plt.imshow(img[:,:,::-1])\n",
    "#顯示圖片\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----人臉轉正\n",
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import time\n",
    "\n",
    "#讀取圖像\n",
    "img = cv2.imread(\"test_img\\\\0009.jpg\")\n",
    "\n",
    "#轉正臉\n",
    "#透過雙眼以及鼻子的位置，調整出正臉\n",
    "faces2 = RetinaFace.extract_faces(img, align = True)\n",
    "\n",
    "for face in faces2:\n",
    "    plt.imshow(face)\n",
    "    plt.show()\n",
    "\n",
    "# plt.imsave('img2.png',image)\n",
    "# plt.savefig(\"img2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----特徵向量\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----比對\n",
    "from retinaface import RetinaFace\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import time\n",
    "\n",
    "#讀取圖像\n",
    "img = cv2.imread(\"test_img\\\\0009.jpg\")\n",
    "img2 = cv2.imread(\"test_img\\\\0002.jpg\")\n",
    "\n",
    "\n",
    "#驗證圖片\n",
    "result = DeepFace.verify(img, img2, model_name = 'ArcFace',detector_backend = 'retinaface',enforce_detection=False)\n",
    "print(\"verify --> \",result,'\\n')\n",
    "\n",
    "#透過RetinaFace辨識人像，默認閾值設置為 0.9。如果要以低解析度檢測人臉，則可以降低它。\n",
    "faces  = RetinaFace.detect_faces(img,threshold = 0.9)\n",
    "faces2  = RetinaFace.detect_faces(img2,threshold = 0.9)\n",
    "\n",
    "#圖像參數\n",
    "print(\"faces --> \",faces,\"\\n\")\n",
    "# print(\"faces.keys() --> \",faces.keys(),\"\\n\")\n",
    "\n",
    "print(\"faces2 --> \",faces2,\"\\n\")\n",
    "# print(\"faces2.keys() --> \",faces2.keys(),\"\\n\")\n",
    "\n",
    "#取出參數\n",
    "for twofaces in [faces,faces2]:\n",
    "    for key in twofaces.keys():\n",
    "\n",
    "        #第X張人像總參數\n",
    "        identity = faces[key]\n",
    "\n",
    "        #人像矩形邊界參數\n",
    "        facial_area = identity[\"facial_area\"]\n",
    "\n",
    "        #特徵標記\n",
    "        landmarks = identity[\"landmarks\"]\n",
    "\n",
    "        #將numpy.float數值轉換為int，因為cv2.circle參數center格式需要int\n",
    "        le = tuple(map(int,landmarks[\"left_eye\"]))\n",
    "        re = tuple(map(int,landmarks[\"right_eye\"]))\n",
    "        n  = tuple(map(int,landmarks[\"nose\"]))\n",
    "        lm = tuple(map(int,landmarks[\"mouth_left\"]))\n",
    "        rm = tuple(map(int,landmarks[\"mouth_right\"]))\n",
    "        \n",
    "        if twofaces == faces:\n",
    "            img = img\n",
    "        else:\n",
    "            img = img2\n",
    "        #框出人像\n",
    "        cv2.rectangle(img, (facial_area[2],facial_area[3]),(facial_area[0],facial_area[1]),(255,255,255),1)\n",
    "        #標記左眼位置\n",
    "        cv2.circle(img, le, 1, (0, 0, 255), -1)\n",
    "        #標記右眼位置\n",
    "        cv2.circle(img, re, 1, (0, 0, 255), -1)\n",
    "        #標記鼻子位置\n",
    "        cv2.circle(img, n, 1, (0, 0, 255), -1)\n",
    "        #標記左嘴角位置\n",
    "        cv2.circle(img, lm, 1, (0, 0, 255), -1)\n",
    "        #標記右嘴角位置\n",
    "        cv2.circle(img, rm, 1, (0, 0, 255), -1)   \n",
    "\n",
    "        #設定顯示圖片大小\n",
    "        plt.figure(figsize = (5,5))\n",
    "        #使圖片顯示完整\n",
    "        plt.imshow(img[:,:,::-1])\n",
    "        #顯示圖片\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl檔案內容\n",
    "import pickle\n",
    "path = 'pic\\\\representations_arcface.pkl'\n",
    "\n",
    "f = open(path,'rb')\n",
    "data = pickle.load(f)\n",
    "\n",
    "print(data[0])\n",
    "print(len(data[0][1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a50661e715ff64d60d8747fa7b1e3af6092d527f01cb31cb7daf74037322f8b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
